# ARACHNID: A Neuromorphic Camera Array System for Space Situational Awareness.  

[![ARACHNID Demo](https://img.youtube.com/vi/LMGO_UEAE98/0.jpg)](https://youtu.be/LMGO_UEAE98)

[Youtube link](https://youtu.be/LMGO_UEAE98)

**ARACHNID** (*Automatic Real-time Aerospace deteCtion Harnessing NeuromorphIc Devices*) is a neuromorphic sensing platform composed of 8 asynchronous *Event-Based Cameras (EBCs)* arranged in a multi-view configuration inspired by arachnid vision. It leverages *Spiking Neural Networks (SNNs)* for real-time, parallel detection of RSOs across multiple fields of view.

---

## Additional Demonstrations

[YouTube Playlist â€“ ARACHNID System Demos](https://www.youtube.com/playlist?list=PLaZnk8KVwCdEpGGF17JUzek4FKIoKYD8W&si=N5XoMQ7-EKGfivss)

---

## EVAS Dataset

The *EVAS (Event-based Vision Artificial Satellites)* dataset is available on Kaggle:  
[EVAS Dataset on Kaggle](https://www.kaggle.com/datasets/sevaldi/grabaciones-satlites)

---

## Development Environment

All code was implemented using:

- **Python** 3.10  
- **Prophesee Metavision SDK** v4.6.2  
- **BrainChip Akida** v3.11  

Development was conducted on **Ubuntu 22.04**, although the code is designed to be cross-platform with minimal adjustments required for other environments.
